## Day 20 : Web Scraping/Extraction

ğŸ” Web Scraping is used to extract relevant data from websites. Also known as screen scraping or web data extraction, web scraping makes it possible to download specific data from web pages based on defined parameters. 
Today I worked with requests and Beautiful soup library to scrap data from https://lnkd.in/gkQ2Xphp

#### Steps involved in scraping data:

**ğŸ›  Install the Requests and Beautiful Soup libraries if not installed:**
 - <p>â­• pip install requests bs4</p>
\
**ğŸ“š Import the libraries:**
 - <p>â­• import requests</p>
 - <p>â­•  from bs4 import BeautifulSoup</p>
\
**ğŸ”— Send a GET request to the website you want to scrape and Check the response status code:**
 - <p>â­• url = "https://lnkd.in/gkQ2Xphp"</p>
 - <p>â­•  response = requests.get(url)</p>
\
**âœ Parse the HTML content:**
 - <p>â­• soup = BeautifulSoup(response.content, "html.parser")</p>
\
**ğŸ•µâ€â™‚ï¸ Locate the elements you want to scrape:**
 - <p>â­•  You can use Beautiful Soup methods like find(), find_all(), select(), and select_one() to locate specific elements in the HTML tree.</p>
\
**ğŸ“ Extract the data from the elements:**
 - <p>â­•  Once you have located the elements, you can use BeautifulSoup methods like get_text(), get() (for attributes), and attrs (for all attributes) to extract the data you want.</p>
\
**ğŸ“ Save the scraped data:**
 - <p>â­•  You can save the scraped data to a file (CSV, JSON, etc.) or store it in a database for further analysis. for more scraping practice check the above site</p>
\
#100DaysOfDataEngineering #DataEngineering #Data
